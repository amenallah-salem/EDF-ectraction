{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pprint\n",
    "from pdf2image import convert_from_path\n",
    "from pytesseract import image_to_string\n",
    "import re\n",
    "import cv2\n",
    "def convert_pdf_to_img(pdf_file):\n",
    "    return convert_from_path(pdf_file)\n",
    "\n",
    "\n",
    "def convert_image_to_text(file):\n",
    "    text = image_to_string(file)\n",
    "    return text\n",
    "\n",
    "\n",
    "def get_text_from_any_pdf(pdf_file):\n",
    "    images = convert_pdf_to_img(pdf_file)\n",
    "    final_output = {}\n",
    "    for pg, img in enumerate(images):\n",
    "        final_output[pg]=convert_image_to_text(img)\n",
    "    return final_output\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "#convert the pdf file inti images : \n",
    "#save them in the saved dir \n",
    "file_name = \"./data/4141_001.pdf\"\n",
    "images = convert_pdf_to_img(file_name)\n",
    "for i in range(len(images)):\n",
    "    images[i].save('page'+ str(i) +'.jpg', 'JPEG')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "def get_text_from_any_pdf(pdf_file):\n",
    "    images = convert_pdf_to_img(pdf_file)\n",
    "    final_output = {}\n",
    "    for pg, img in enumerate(images):\n",
    "        final_output[pg]=convert_image_to_text(img)\n",
    "    return final_output\n",
    "def text_preprocess(txt):\n",
    "    txt = txt.replace('\\n\\n', '\\n').split('\\n')\n",
    "    #print(txt)\n",
    "    return txt\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "#OK let's grab one ilage from the saved images \n",
    "img = cv2.imread(\"/home/amenallah/Desktop/CEREBRA_PROJECTS-AWS/EDF/back_end/extractify/tests/page0.jpg\")\n",
    "cv2.imshow('frma', cv2.cvtColor(img, cv2.COLOR_BGR2RGB))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "help(cv2.imshow)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Help on built-in function imshow:\n",
      "\n",
      "imshow(...)\n",
      "    imshow(winname, mat) -> None\n",
      "    .   @brief Displays an image in the specified window.\n",
      "    .   \n",
      "    .   The function imshow displays an image in the specified window. If the window was created with the\n",
      "    .   cv::WINDOW_AUTOSIZE flag, the image is shown with its original size, however it is still limited by the screen resolution.\n",
      "    .   Otherwise, the image is scaled to fit the window. The function may scale the image, depending on its depth:\n",
      "    .   \n",
      "    .   -   If the image is 8-bit unsigned, it is displayed as is.\n",
      "    .   -   If the image is 16-bit unsigned or 32-bit integer, the pixels are divided by 256. That is, the\n",
      "    .       value range [0,255\\*256] is mapped to [0,255].\n",
      "    .   -   If the image is 32-bit or 64-bit floating-point, the pixel values are multiplied by 255. That is, the\n",
      "    .       value range [0,1] is mapped to [0,255].\n",
      "    .   \n",
      "    .   If window was created with OpenGL support, cv::imshow also support ogl::Buffer , ogl::Texture2D and\n",
      "    .   cuda::GpuMat as input.\n",
      "    .   \n",
      "    .   If the window was not created before this function, it is assumed creating a window with cv::WINDOW_AUTOSIZE.\n",
      "    .   \n",
      "    .   If you need to show an image that is bigger than the screen resolution, you will need to call namedWindow(\"\", WINDOW_NORMAL) before the imshow.\n",
      "    .   \n",
      "    .   @note This function should be followed by cv::waitKey function which displays the image for specified\n",
      "    .   milliseconds. Otherwise, it won't display the image. For example, **waitKey(0)** will display the window\n",
      "    .   infinitely until any keypress (it is suitable for image display). **waitKey(25)** will display a frame\n",
      "    .   for 25 ms, after which display will be automatically closed. (If you put it in a loop to read\n",
      "    .   videos, it will display the video frame-by-frame)\n",
      "    .   \n",
      "    .   @note\n",
      "    .   \n",
      "    .   [__Windows Backend Only__] Pressing Ctrl+C will copy the image to the clipboard.\n",
      "    .   \n",
      "    .   [__Windows Backend Only__] Pressing Ctrl+S will show a dialog to save the image.\n",
      "    .   \n",
      "    .   @param winname Name of the window.\n",
      "    .   @param mat Image to be shown.\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('demo': conda)"
  },
  "interpreter": {
   "hash": "c5323fd0b3b1866eb9c464bce345898f25029c5f73e2e17765f52aaffff033f5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}